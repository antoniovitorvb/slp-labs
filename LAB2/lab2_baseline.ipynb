{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKktKs1C-x4D"
   },
   "source": [
    "# Speech Processing - Instituto Superior Técnico\n",
    "### Laboratory Assignment 2 - Spoken Language Indentification challenge\n",
    "\n",
    "The second laboratory assignment of the course is designed to simulate a **spoken language identification** challenge. In this challenge, partipants (a.k.a students enrolled in the course) receive a train, development and evaluation (blind) data set, and a simple (and weak) baseline system for the task at hand: closed-set identification of the spoken language in a given audio file out of a set of six target langauges: Basque,  Catalan,  English,  Galician,  Portuguese and  Spanish.\n",
    "\n",
    "The **goal** for each participant is to develop/build the best spoken language identification system. To this end, participants are encouraged to modify this baseline, incorporate any other techniques and in general explore any approach that permit  improving their results.\n",
    "\n",
    "During the first week (Part 1), students are expected to:\n",
    "- Run and understand the main components of the baseline.\n",
    "- Propose and develop simple modifications to the baseline feature extraction process.\n",
    "- Propose and develop simple modifications to the baseline GMM language models.\n",
    "- Evaluate the models on the development partition.\n",
    "\n",
    "During the second week (Part 2), students are expected to:\n",
    "- Propose and develop other *classical* modifications to any component of the processing pipeline (openSMILE features, segment-based features, SVM classifiers, MLP/CNN classifiers, etc.)\n",
    "- Run and understand the second part of Notebook that explores a pre-trained model.\n",
    "- Propose and develop more recent advanced approaches, including x-vectors.\n",
    "- Evaluate the models on the development partition.\n",
    "- Obtain predictions for the blind test partition and prepare the submission.\n",
    "\n",
    "The challenge distinguishes two different tracks or evaluation conditions:\n",
    "- Track 1 - Participants are not allowed to use any kind of pre-trained model (such as x-vectors).\n",
    "- Track 2 - Participants are allowed to use anything.\n",
    "\n",
    "\n",
    "## About the data\n",
    "\n",
    "The data consists of mono audio files sampled at 16 kHz all of them containing speech of only one of the following target languages:\n",
    "```python \n",
    "LANGUAGES = ('Basque',  'Catalan',  'English',  'Galician',  'Portuguese',  'Spanish')\n",
    "```\n",
    "\n",
    "The dataset is organized in 4 partitions:\n",
    "- `'train'`: This is the full training set, consisting of 3060 clean audio samples correponding to speech segments of TV broadcast shows. (**ATENTION**: Do not use this dataset for training your models, unless your system is very fast or if you want to build your final model. It can be slow)\n",
    "- `'train100'`: This is a subset of the full training set that consists of 100 audio files per target language (**RECOMMENDATION**: Use this partition in your quick experiments, to more rapidly validate alternatives)\n",
    "- `'dev'`: This is the development set. It contains audio extracted from YouTube. You will typically use this to validate the quality of your model.\n",
    "- `'evl'`: This is the evaluation set. It contains audio extracted from YouTube. You don't have the groud-truth for this set. You are expected to produce it and submit it.\n",
    "\n",
    "The data used in this challenge is a subset of the KALAKA-3 database: https://aclanthology.org/L14-1576/\n",
    "\n",
    "The  difference is that only the clean train audio segments and the Plenty Closed evaluation condition have been considered. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFKBJg-k_9E2"
   },
   "source": [
    "## Before starting\n",
    "The following conditions are neecessary to run correctly this notebook:\n",
    "\n",
    "*   All modules included in the requirements file need to be \n",
    "installed in the Python environment.\n",
    "*   The module `pf_tools` needs to be accessible (if you are using Google Colab, you will need to copy the `pf_tools.py` every time you start a new session).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Pg8jtmPLBXAP"
   },
   "outputs": [],
   "source": [
    "from pf_tools import CheckThisCell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47sWqJwa-x4F"
   },
   "source": [
    "## How can you download (and process) the data\n",
    "\n",
    "The first thing we have to do is to set our working directory. If you are using Google Colab, you  probably want to mount Google Drive to keep persistent information, such as data, features and models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Yl6Yy5bd-6rI"
   },
   "outputs": [],
   "source": [
    "#raise CheckThisCell ## <---- Remove this torun this cell if you are on Google Colab\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BVCxu-Ln-x4G"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ritas\\\\OneDrive - Universidade de Lisboa\\\\Ambiente de Trabalho\\\\MECD\\\\Processamento Fala\\\\Lab2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#raise CheckThisCell ## <---- Remove this after completeing/checking this cell\n",
    "import os \n",
    "CWD = os.getcwd() + '' # Change this variable to your working directory to store data, features and models\n",
    "CWD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TINbywJr-x4H"
   },
   "source": [
    "The class `Kalaka` permits downloading, transforming and storing the different data partitions. Each `Kalaka` instance can be used to iterate over all the samples of the partition. It can also be used in combination with pytorch dataloader to read batches of data to train neural networks with pytorch. For instance, consider the following piece of code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "yZCZhc5I-x4I"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ritas\\OneDrive - Universidade de Lisboa\\Ambiente de Trabalho\\MECD\\Processamento Fala\\Lab2\\pf_tools.py:89: UserWarning: The feature directory already exists, and no new feature extraction will be performed.\n",
      "  warnings.warn(\"The feature directory already exists, and no new feature extraction will be performed.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pf_tools import Kalaka\n",
    "import librosa \n",
    "\n",
    "def audio_transform(filename):\n",
    "    y, _ = librosa.load(filename, sr=16000, mono=True)\n",
    "    return y.reshape(-1,1)\n",
    "    \n",
    "trainkalaka = Kalaka(CWD, 'train100', transform_id='raw', audio_transform=audio_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Daa8nvX-x4I"
   },
   "source": [
    "\n",
    "This will first download and uncompress the .tar.gz file containing all the necessary data of the `'train100'` partition, that is, the audio files that are stored to disk (in CWD/train100/audio/) and key file (CWD/train100/key.lst). Then, the audio transformation `'transform'` will be applied to each file and the result stored to disk CWD/train100/raw/. \n",
    "\n",
    "**Audio transformations** receive a filename of an audio file and returns an array of dimensions (NxD), in which N is the time dimension and D the dimension of the feature vector. In this simple case D is 1 because the transform is just returning the raw audio signal.\n",
    "\n",
    "The `Kalaka` class permits chunking the output of the audio transformation (of size NxD) in chunks of CxD size. The chunking operation divides the orignal sample, in multiple smaller samples with a configurable chunk size and hop length. These chunks can be further transformed and stored as individual feature files. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "GgtHHvcc-x4I"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/600 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numba' has no attribute 'core'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainkalaka \u001b[38;5;241m=\u001b[39m \u001b[43mKalaka\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCWD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain100\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mtransform_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchunks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                     \u001b[49m\u001b[43maudio_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maudio_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m16000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mchunk_hop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m16000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive - Universidade de Lisboa\\Ambiente de Trabalho\\MECD\\Processamento Fala\\Lab2\\pf_tools.py:53\u001b[0m, in \u001b[0;36mKalaka.__init__\u001b[1;34m(self, root, dataset_id, transform_id, audio_transform, chunk_size, chunk_hop, chunk_transform)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_hop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_size\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_data(Kalaka\u001b[38;5;241m.\u001b[39mRELEASE_CONFIGS[dataset_id][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchecksum\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 53\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_to_feat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_file):\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey file does not exist. There was some problem downloading data.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\OneDrive - Universidade de Lisboa\\Ambiente de Trabalho\\MECD\\Processamento Fala\\Lab2\\pf_tools.py:111\u001b[0m, in \u001b[0;36mKalaka.data_to_feat\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    108\u001b[0m     os\u001b[38;5;241m.\u001b[39mmkdir(featOutPath)\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# print(f'\\t{audioin}...', end='')\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m feats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43maudioin\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# The output of this is (Ntime x Dim)\u001b[39;00m\n\u001b[0;32m    113\u001b[0m finish \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36maudio_transform\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maudio_transform\u001b[39m(filename):\n\u001b[1;32m----> 6\u001b[0m     y, _ \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m(filename, sr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16000\u001b[39m, mono\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\lazy_loader\\__init__.py:77\u001b[0m, in \u001b[0;36mattach.<locals>.__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     75\u001b[0m submod_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_to_modules[name]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     76\u001b[0m submod \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(submod_path)\n\u001b[1;32m---> 77\u001b[0m attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# If the attribute lives in a file (module) with the same\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# name as the attribute, ensure that the attribute and *not*\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# the module is accessible on the package.\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m attr_to_modules[name]:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\lazy_loader\\__init__.py:76\u001b[0m, in \u001b[0;36mattach.<locals>.__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m attr_to_modules:\n\u001b[0;32m     75\u001b[0m     submod_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_to_modules[name]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 76\u001b[0m     submod \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubmod_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m     attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(submod, name)\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;66;03m# If the attribute lives in a file (module) with the same\u001b[39;00m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;66;03m# name as the attribute, ensure that the attribute and *not*\u001b[39;00m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m# the module is accessible on the package.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:850\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:1145\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m   1139\u001b[0m         bwd_pred_error \u001b[38;5;241m=\u001b[39m bwd_pred_error[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ar_coeffs\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;129;43m@stencil\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m-> 1145\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43m_zc_stencil\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndarray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzero_pos\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndarray\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43;03m\"\"\"Stencil to compute zero crossings\"\"\"\u001b[39;49;00m\n\u001b[0;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\stencils\\stencil.py:813\u001b[0m, in \u001b[0;36mstencil\u001b[1;34m(func_or_mode, **options)\u001b[0m\n\u001b[0;32m    811\u001b[0m wrapper \u001b[38;5;241m=\u001b[39m _stencil(mode, options)\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\stencils\\stencil.py:823\u001b[0m, in \u001b[0;36m_stencil.<locals>.decorated\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compiler\n\u001b[0;32m    822\u001b[0m kernel_ir \u001b[38;5;241m=\u001b[39m compiler\u001b[38;5;241m.\u001b[39mrun_frontend(func)\n\u001b[1;32m--> 823\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mStencilFunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkernel_ir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\stencils\\stencil.py:83\u001b[0m, in \u001b[0;36mStencilFunc.__init__\u001b[1;34m(self, kernel_ir, mode, options)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_typingctx \u001b[38;5;241m=\u001b[39m registry\u001b[38;5;241m.\u001b[39mcpu_target\u001b[38;5;241m.\u001b[39mtyping_context\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_targetctx \u001b[38;5;241m=\u001b[39m registry\u001b[38;5;241m.\u001b[39mcpu_target\u001b[38;5;241m.\u001b[39mtarget_context\n\u001b[1;32m---> 83\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_typingctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefresh\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_targetctx\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_install_type(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_typingctx)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\core\\typing\\context.py:160\u001b[0m, in \u001b[0;36mBaseContext.refresh\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_additional_registries()\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# Some extensions may have augmented the builtin registry\u001b[39;00m\n\u001b[1;32m--> 160\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_builtins\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\core\\typing\\context.py:421\u001b[0m, in \u001b[0;36mBaseContext._load_builtins\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ctypes_utils, bufproto           \u001b[38;5;66;03m# noqa: F401, E501\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munsafe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m eh                    \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m--> 421\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstall_registry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemplates\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuiltin_registry\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\core\\typing\\context.py:441\u001b[0m, in \u001b[0;36mBaseContext.install_registry\u001b[1;34m(self, registry)\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minsert_function(ftcls(\u001b[38;5;28mself\u001b[39m))\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ftcls \u001b[38;5;129;01min\u001b[39;00m loader\u001b[38;5;241m.\u001b[39mnew_registrations(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattributes\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 441\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minsert_attributes(\u001b[43mftcls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gv, gty \u001b[38;5;129;01min\u001b[39;00m loader\u001b[38;5;241m.\u001b[39mnew_registrations(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglobals\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    443\u001b[0m     existing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lookup_global(gv)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\core\\typing\\templates.py:1054\u001b[0m, in \u001b[0;36m_OverloadAttributeTemplate.__init__\u001b[1;34m(self, context)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28msuper\u001b[39m(_OverloadAttributeTemplate, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(context)\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext \u001b[38;5;241m=\u001b[39m context\n\u001b[1;32m-> 1054\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\core\\typing\\templates.py:1104\u001b[0m, in \u001b[0;36m_OverloadMethodTemplate._init_once\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1101\u001b[0m attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attr\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1104\u001b[0m     registry \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_target_registry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmethod\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1105\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InternalTargetMismatchError:\n\u001b[0;32m   1106\u001b[0m     \u001b[38;5;66;03m# Target mismatch. Do not register attribute lookup here.\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\core\\typing\\templates.py:947\u001b[0m, in \u001b[0;36m_TemplateTargetHelperMixin._get_target_registry\u001b[1;34m(self, reason)\u001b[0m\n\u001b[0;32m    924\u001b[0m tgtctx \u001b[38;5;241m=\u001b[39m disp\u001b[38;5;241m.\u001b[39mtargetdescr\u001b[38;5;241m.\u001b[39mtarget_context\n\u001b[0;32m    925\u001b[0m \u001b[38;5;66;03m# This is all workarounds...\u001b[39;00m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;66;03m# The issue is that whilst targets shouldn't care about which registry\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;66;03m# in which to register lowering implementations, the CUDA target\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[38;5;66;03m# In case the target has swapped, e.g. cuda borrowing cpu, refresh to\u001b[39;00m\n\u001b[0;32m    946\u001b[0m \u001b[38;5;66;03m# populate.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m \u001b[43mtgtctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefresh\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m builtin_registry \u001b[38;5;129;01min\u001b[39;00m tgtctx\u001b[38;5;241m.\u001b[39m_registries:\n\u001b[0;32m    949\u001b[0m     reg \u001b[38;5;241m=\u001b[39m builtin_registry\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\core\\base.py:275\u001b[0m, in \u001b[0;36mBaseContext.refresh\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03mRefresh context with new declarations from known registries.\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;124;03mUseful for third-party extensions.\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;66;03m# load target specific registries\u001b[39;00m\n\u001b[1;32m--> 275\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_additional_registries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;66;03m# Populate the builtin registry, this has to happen after loading\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;66;03m# additional registries as some of the \"additional\" registries write\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;66;03m# their implementations into the builtin_registry and would be missed if\u001b[39;00m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;66;03m# this ran first.\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstall_registry(builtin_registry)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numba\\core\\cpu.py:97\u001b[0m, in \u001b[0;36mCPUContext.load_additional_registries\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstall_registry(jitclassimpl\u001b[38;5;241m.\u001b[39mclass_impl_registry)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# load 3rd party extensions\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m \u001b[43mnumba\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore\u001b[49m\u001b[38;5;241m.\u001b[39mentrypoints\u001b[38;5;241m.\u001b[39minit_all()\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numba' has no attribute 'core'"
     ]
    }
   ],
   "source": [
    "trainkalaka = Kalaka(CWD, 'train100', \n",
    "                     transform_id='chunks', \n",
    "                     audio_transform=audio_transform, \n",
    "                     chunk_size=4*16000, \n",
    "                     chunk_hop=2*16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6jSp12Y-x4J"
   },
   "source": [
    "This will download and uncompress the partition data, only if was not already done before. Then, as previously, the simple tranform that returns the waveform is applied to each audio file. After this, the resulting array of dimension Nx1, in which N=16000xduration_in_seconds, is split in continuous chunks of length 64000 (that is, 4 seconds) with chunk hop of 2 seconds. Each one of these chunks of 4 seconds is stored and will be accessed whenever we iterate the dataset. \n",
    "\n",
    "Adittionally, the optional argument `chunk_transform` pertmits defining a transformation to be applied to each chunk before storing to disk. It can be any function that receives an array of size CxD and returns an array HxW, in which H is the *new time dimension*. For instance, the following example takes the audio segments of 64000x1, computes the mean and variance every 0.1 sec (1600 samples) and returns a feature vector of size 40x2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4TEyYZqP-x4J"
   },
   "outputs": [],
   "source": [
    "def chunk_transform(x):\n",
    "    x = x.reshape(-1,1600)\n",
    "    return np.concatenate((x.mean(axis=1, keepdims=True), x.std(axis=1, keepdims=True)),axis=1)\n",
    "\n",
    "trainkalaka = Kalaka(CWD, 'train100', \n",
    "                     transform_id='chunks_mv', \n",
    "                     audio_transform=audio_transform, \n",
    "                     chunk_size=4*16000, \n",
    "                     chunk_hop=2*16000, \n",
    "                     chunk_transform=chunk_transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gDeoLfmr-x4J"
   },
   "source": [
    "\n",
    "Notice that, while the above example is probably useless as an effective feature extraction method, the proper combination of audio and chunk transformations is expected to permit quite flexible feature extraction that (hopefully) can match the needs of almost any training setting. \n",
    "\n",
    "Once we have instanciated a Kalaka dataset, it can be iterated to have access to each processed sample, for instance: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "wnNfbbfo-x4K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (40, 2) 6 0006ebda\n",
      "1000 (40, 2) 1 11a3790f\n",
      "2000 (40, 2) 4 271621da\n",
      "3000 (40, 2) 5 3b9d2c2f\n",
      "4000 (40, 2) 1 4d10f8f2\n",
      "5000 (40, 2) 6 5fb949a1\n",
      "6000 (40, 2) 6 70d28e30\n",
      "7000 (40, 2) 6 7d5515f0\n",
      "8000 (40, 2) 3 937623c2\n",
      "9000 (40, 2) 5 a4a7491b\n",
      "10000 (40, 2) 5 bc3f6e51\n",
      "11000 (40, 2) 3 cd82bcca\n",
      "12000 (40, 2) 1 df0b27f2\n",
      "13000 (40, 2) 3 f3ba1f4d\n",
      "Finished reading all data in 11.870569944381714\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "for i, sample in enumerate(trainkalaka):\n",
    "    data, label, basename = sample # array, int, str\n",
    "    if i % 1000 == 0:\n",
    "        print(i, data.shape, label, basename)\n",
    "\n",
    "print(f'Finished reading all data in {time.time() - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1aDkyB-J-x4K"
   },
   "source": [
    "Now you can use the `Kalaka` class to check the  number of files and size (in minutes) of the training set for each target language. You can keep these numbers to include in your system description paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "XPxjJ72Z-x4K"
   },
   "outputs": [],
   "source": [
    "# Inspect the training data to find the size of each training language.\n",
    "# You can instanciate again the Kalaka class with the raw configuration to retrieve audio samples\n",
    "#raise CheckThisCell ## <---- Remove this after completeing/checking this cell\n",
    "LANGUAGES = ('Basque',  'Catalan',  'English',  'Galician',  'Portuguese',  'Spanish')\n",
    "LANG2ID = {'Basque':1, 'Catalan':2, 'English':3, 'Galician':4, 'Portuguese':5, 'Spanish':6}\n",
    "ID2LANG = dict((LANG2ID[k],k)for k in LANG2ID)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dO5uyX3T-x4L"
   },
   "source": [
    "Notice that the `Kalaka` class extends the `torch.utils.data.Dataset` and it can be used in combination with a Pytorch DataLoader to read data in batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qI7v2O-4-x4L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 40, 2]) torch.Size([10]) 10\n",
      "torch.Size([10, 40, 2]) torch.Size([10]) 10\n",
      "torch.Size([10, 40, 2]) torch.Size([10]) 10\n",
      "torch.Size([10, 40, 2]) torch.Size([10]) 10\n",
      "torch.Size([10, 40, 2]) torch.Size([10]) 10\n",
      "torch.Size([10, 40, 2]) torch.Size([10]) 10\n",
      "torch.Size([10, 40, 2]) torch.Size([10]) 10\n",
      "torch.Size([10, 40, 2]) torch.Size([10]) 10\n",
      "torch.Size([10, 40, 2]) torch.Size([10]) 10\n",
      "torch.Size([10, 40, 2]) torch.Size([10]) 10\n",
      "torch.Size([10, 40, 2]) torch.Size([10]) 10\n",
      "torch.Size([10, 40, 2]) torch.Size([10]) 10\n",
      "torch.Size([10, 40, 2]) torch.Size([10]) 10\n",
      "torch.Size([10, 40, 2]) torch.Size([10]) 10\n",
      "Finished reading all data in 8.163986921310425\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "trainkalaka = Kalaka(CWD, 'train100', \n",
    "                     transform_id='chunks_mv', \n",
    "                     audio_transform=audio_transform, \n",
    "                     chunk_size=4*16000, \n",
    "                     chunk_hop=2*16000, \n",
    "                     chunk_transform=chunk_transform)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=trainkalaka,\n",
    "        batch_size=10,\n",
    "        shuffle=True\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "for i, batch in enumerate(dataloader):\n",
    "    data, label, basename = batch\n",
    "    if i % 100 == 0:\n",
    "        print(data.shape, label.shape, len(basename))\n",
    "\n",
    "print(f'Finished reading all data in {time.time() - start}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0MtRjdL-x4L"
   },
   "source": [
    "Finally, remind that you can change anything you want. This includes the Kalaka class. Eventually, you can decide not using it at all and loading the data in some alternative way.  You can inspect the class to find the URLs for downloading the datasets. It is up to you! \n",
    "\n",
    "Before moving to the next stage, you probably want to delete the folders containing the dummy features that you just generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7i8g-3uW-x4M"
   },
   "source": [
    "# PART 1 - The baseline (Track 1)\n",
    "The baseline consists of MFCC feature extraction  (based on the `librosa` module) with SDC computation and VAD removal, followed by GMMs of 64 dimensions for each language (using the `sklearn` module). The rest of this notebook contains the guide and code cells (some of them partially incomplete) that permit implementing this baseline and score it on the development set. Read carefully the Markdown information, but also the comments inside the code cells (they provide useful information and hints), and also the code itself. The better you understand it, the easier will be modyfing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54fizt_y-x4M"
   },
   "source": [
    "## Initialization and importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KD4G6kwm-x4M"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pf_tools import Kalaka\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import csv \n",
    "from tqdm import tqdm\n",
    "\n",
    "GLOBAL_SEED = 35731\n",
    "\n",
    "np.random.seed(GLOBAL_SEED)\n",
    "torch.manual_seed(GLOBAL_SEED)\n",
    "random.seed(GLOBAL_SEED)\n",
    "\n",
    "\n",
    "LANGUAGES = ('Basque',  'Catalan',  'English',  'Galician',  'Portuguese',  'Spanish')\n",
    "LANG2ID = {'Basque':1, 'Catalan':2, 'English':3, 'Galician':4, 'Portuguese':5, 'Spanish':6}\n",
    "ID2LANG = dict((LANG2ID[k],k)for k in LANG2ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9FMo-Pb-x4N"
   },
   "source": [
    "## The baseline feature extraction module\n",
    "The next function extracts MFCCs, but there are plenty of things that can be improved. You are free to change anything you want, including the number of formal parameters, the number of returned expressions, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WVwAhGEv-x4N"
   },
   "outputs": [],
   "source": [
    "# Read carefully this function and understand it\n",
    "# raise CheckThisCell ## <---- Remove this after completeing/checking this cell\n",
    "\n",
    "def feat_extract(filename, orig_sr=16000, mono=True, n_mfcc = 13, remove_c0=False, delta_order=0, apply_sdc=False, apply_vad=False, apply_cmvn=False):\n",
    "    \n",
    "    sr=16000\n",
    "    n_mels = 40\n",
    "    n_fft = 512 \n",
    "    hop_length = 160\n",
    "    fmin = 50\n",
    "    fmax = 7800\n",
    "    \n",
    "    if apply_sdc and (delta_order > 0):\n",
    "        raise ValueError(\"Applying SDC and delta > 0 is not compatible\")\n",
    "\n",
    "\n",
    "    # Load audio wav into numpy array\n",
    "    y, _ = librosa.load(filename, sr=orig_sr, mono=mono)\n",
    "    \n",
    "    # Resample in case it's needed\n",
    "    if orig_sr != sr:\n",
    "        y = librosa.resample(y, orig_sr=orig_sr,target_sr=sr)\n",
    "\n",
    "    ## OPTIONAL ADDIDITIONAL STAGES - LAB WORK\n",
    "    # 1 - PREPROCESSING - Typical preprocessing may include normalization of audio (mean removal), \n",
    "    #                       but also speech enhancement and others more complex\n",
    "    \n",
    "    # Extract MFFCs\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_fft=n_fft, \n",
    "                                n_mfcc=n_mfcc, n_mels=n_mels, \n",
    "                                hop_length=hop_length, \n",
    "                                fmin=fmin, fmax=fmax, htk=False).T\n",
    "    \n",
    "    ## OPTIONAL ADDIDITIONAL STAGES - LAB WORK\n",
    "\n",
    "    # 2 Compute deltas --> Hint you can use librosa (order size may be a parameter?)\n",
    "    if delta_order > 0:\n",
    "        mfcc = compute_delta(mfcc,delta_order=delta_order)\n",
    "    \n",
    "    # 3 SDC --> Hint: You can build this using deltas (of extented context)  \n",
    "    if apply_sdc:\n",
    "        mfcc = compute_sdc(mfcc)\n",
    "    \n",
    "    # 4 COMPUTE VAD --> Hint: You can use any vad (theshold energy, something avaialble in the net, a biGaussian model...).\n",
    "    #                         Coeff0 is highly related with Energy and sometimes it is removed\n",
    "    #                   ATTENTION: Using a VAD may have a significant impact  \n",
    "    if apply_vad:\n",
    "        mfcc, _ = compute_vad(mfcc)\n",
    "             \n",
    "    # 5 APPLY CMVN --> ATTENTION: Using normalization may have a significant impact\n",
    "    if apply_cmvn:\n",
    "        mfcc = compute_cmvn(mfcc)\n",
    "\n",
    "    return mfcc, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkDh_Dkv-x4O"
   },
   "source": [
    "Try to define some or all of the following steps to improve your feature extraction pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Z4aI1NrH-x4O"
   },
   "outputs": [],
   "source": [
    "# Numpy arrays have methods to compute mean and variance, so this one should be really easy\n",
    "#raise CheckThisCell ## <---- Remove this after completeing/checking this cell\n",
    "\n",
    "def compute_cmvn(features):\n",
    "    #return features/np.linalg.norm(features)\n",
    "    return (features-np.mean(features))/np.std(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Nl0eZbV9-x4O"
   },
   "outputs": [],
   "source": [
    "# librosa contains functions to compute deltas\n",
    "#raise CheckThisCell ## <---- Remove this after completeing/checking this cell\n",
    "\n",
    "def compute_delta(features, win=3, delta_order=2, keep_static=True):\n",
    "    delta=librosa.feature.delta(features,width=win,order=delta_order)\n",
    "    return np.hstack((features,delta))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Fd6EZp7h-x4O"
   },
   "outputs": [],
   "source": [
    "# Compute deltas and then select previous and next deltas with fixed intervals to cocatentate. \n",
    "# You may need to code a bit here or dinf some function that helps with this\n",
    "#raise CheckThisCell ## <---- Remove this after completeing/checking this cell\n",
    "\n",
    "def compute_sdc(features, P=3, D=3, K=2, keep_static=True):\n",
    "    delta=compute_delta(features,win=D,delta_order=1)[:,np.shape(features)[1]:]\n",
    "    \n",
    "    sdc=np.empty([np.shape(features)[0],np.shape(features)[1]*K])\n",
    "    marker = np.zeros(features.shape[0], dtype='bool')\n",
    "    for j in range(K):\n",
    "        marker[D + j * P] = True\n",
    "    for i in range(len(features)):\n",
    "        sdc[i, :] = delta[marker, :].reshape(1, -1)\n",
    "        marker = np.roll(marker, 1)\n",
    "    return np.hstack((features,sdc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "nPcV76v8-x4P"
   },
   "outputs": [],
   "source": [
    "# You can think of several strattegies to compute VAD, simple ones based on energy and a threshold, or maybe some more \n",
    "# ellaborated ones, like training a GMM with 2 mixtures with the Energy. \n",
    "# In addition to the features without some frames, this function may return a sequence of 0s and 1s that helps you to validate the method.\n",
    "#raise CheckThisCell ## <---- Remove this after completeing/checking this cell\n",
    "def zero_crossing_rate(x):\n",
    "    return np.sum(np.abs(np.diff(np.sign(x)))/2)/len(x)\n",
    "\n",
    "def compute_vad(features, energy=None, y=None):\n",
    "    features_aux=features[:,0:int(np.shape(features)[1]/2)]\n",
    "    zcr=np.empty(np.shape(features)[1])\n",
    "    for i in range(len(zcr)):\n",
    "        zcr[i]=zero_crossing_rate(features[:,i])\n",
    "    GM=GaussianMixture(n_components=2)\n",
    "    frame_class=GM.fit_predict(zcr.reshape(-1,1))\n",
    "    vad=np.empty(np.shape(features))\n",
    "    for i in range(len(zcr)):\n",
    "        vad[:,i]=frame_class[i]\n",
    "    return np.hstack((features,vad)),frame_class\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DLoKKFw-x4P"
   },
   "source": [
    "You can test in an isolated audio file and inspect the dimensions, verify that your code is doing what is expected, inspect and visualize the data using some of the lessons learnt in LAB1. Also, don't forget to listen some of the examples!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Ug1O-T6w-x4P"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ritas\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#raise CheckThisCell ## <---- Remove this after completeing/checking this cell\n",
    "mfcc, _=feat_extract(f'{CWD}/train100/audio/0006ebda.wav', apply_cmvn=True, apply_sdc=False,apply_vad=False)\n",
    "mfcc_sdc, _ = feat_extract(f'{CWD}/train100/audio/0a58b1ca.wav', apply_cmvn=False, apply_sdc=True)\n",
    "mfcc_dd, _ = feat_extract(f'{CWD}/train100/audio/0006ebda.wav', apply_cmvn=False, delta_order=2)\n",
    "mfcc_d, _ = feat_extract(f'{CWD}/train100/audio/0006ebda.wav', apply_cmvn=True, delta_order=1,apply_vad=True)\n",
    "mfcc_cmvn, y = feat_extract(f'{CWD}/train100/audio/0006ebda.wav', apply_cmvn=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4790, 39)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(mfcc_sdc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ON65_Pf-x4Q"
   },
   "source": [
    "To run the data processing stage for the train100 partition we will simply instanciate the Kalaka class as mentioned previosly. Take a sit because it can take a bit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0ASYLlrc-x4Q"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [03:02<00:00,  3.28it/s]\n"
     ]
    }
   ],
   "source": [
    "transform = { 'mfcc_sdc_vad_chunk_300_400' : \n",
    "                 { \n",
    "                     'audio_transform': lambda x : feat_extract(x, orig_sr=16000, mono=True, n_mfcc = 7, apply_sdc=False, apply_vad=False, apply_cmvn=True)[0],\n",
    "                     'chunk_transform': None,\n",
    "                     'chunk_size': 300,\n",
    "                     'chunk_hop':300\n",
    "                 },\n",
    "                 'mfcc_delta1_vad' : \n",
    "                 { \n",
    "                     'audio_transform': lambda x : feat_extract(x, orig_sr=16000, mono=True,delta_order=1, n_mfcc = 13, apply_sdc=False, apply_vad=True, apply_cmvn=True)[0],\n",
    "                     'chunk_transform': None,\n",
    "                     'chunk_size': 300,\n",
    "                     'chunk_hop':300\n",
    "                 },\n",
    "                 'mfcc_sdc' : \n",
    "                 { \n",
    "                     'audio_transform': lambda x : feat_extract(x, orig_sr=16000, mono=True,delta_order=0, n_mfcc = 13, apply_sdc=True, apply_vad=False, apply_cmvn=True)[0],\n",
    "                     'chunk_transform': None,\n",
    "                     'chunk_size': 300,\n",
    "                     'chunk_hop':300\n",
    "                 },\n",
    "                 'mfcc_delta1' : \n",
    "                 { \n",
    "                     'audio_transform': lambda x : feat_extract(x, orig_sr=16000, mono=True,delta_order=1, n_mfcc = 13, apply_sdc=False, apply_vad=False, apply_cmvn=True)[0],\n",
    "                     'chunk_transform': None,\n",
    "                     'chunk_size': 300,\n",
    "                     'chunk_hop':300\n",
    "                 },\n",
    "            }\n",
    "\n",
    "\n",
    "trainset = 'train100'\n",
    "transform_id = 'mfcc_delta1'\n",
    "\n",
    "trainkalaka = Kalaka(CWD, trainset, \n",
    "                 transform_id=transform_id, \n",
    "                 audio_transform=transform[transform_id]['audio_transform'], \n",
    "                 chunk_transform=transform[transform_id]['chunk_transform'],\n",
    "                 chunk_size=transform[transform_id]['chunk_size'], \n",
    "                 chunk_hop=transform[transform_id]['chunk_hop']\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ooKgrjF5-x4Q"
   },
   "source": [
    "Check your current folder, many things happened!! \n",
    "\n",
    "Notice that if you instanciate again the Kalaka class for the 'train100' partition, the data will not be downloaded again. \n",
    "Additionally, if there is already a folder with the name `transform_id`, feature extraction will not run again. You need to delete from your filesystem the folder with the features if you want to run again the feature extraction (using the same identifier) or , alternatively, you can change the identifier. Be careful because you can easily increase the amount of data generated. If you try a feature extraction method that provides bad results, you probably don't want to keep the features in disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfhB3YHI-x4Q"
   },
   "source": [
    "## The baseline spoken language models\n",
    "The baseline model is extremely simple: we'll train an individual GMM model for each language on top of the features that we just extracted. Later, in prediction time, given a test audio sample, we'll compute the loglikelihood obtained with each GMM model and select as the identified language the one whose model gives the highest likelihood. Let's go for it!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "PV8o37cU-x4Q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading all data in 7.720320463180542\n"
     ]
    }
   ],
   "source": [
    "# IN GMM training each training sample contains more than one frame;\n",
    "# so we cocatenate all data to have all training datain one array \n",
    "# and the corresponding label with same time duration\n",
    "# actually, here the chunking process is useless, I could have obtained the same without chunking (with slight differences due to trunkation)\n",
    "\n",
    "start = time.time()\n",
    "train_data = []\n",
    "train_labels = []\n",
    "for data, label, basename in trainkalaka:\n",
    "        train_data.append(data)\n",
    "        train_labels.append(np.full(data.shape[0], label)) \n",
    "\n",
    "train_data = np.concatenate(train_data)\n",
    "train_labels = np.concatenate(train_labels)\n",
    "\n",
    "print(f'Finished reading all data in {time.time() - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yUYxg6D-x4Q"
   },
   "source": [
    "Now we have two arrays containing the complete training dataset and the corresponging reference labels. Check the sizes, may be have a look to the content of one time instant. Do some checks on the data to be sure that everything is as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vb-zW_Fp-x4R"
   },
   "outputs": [],
   "source": [
    "# Check again the traininig data. Notice that if you apply VAD, the size of the training data must be smaller than the complete data set. \n",
    "# Register the size in frames and in time of training data for each language\n",
    "raise CheckThisCell ## <---- Remove this after completeing/checking this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0c4pMhMj-x4R"
   },
   "source": [
    "Let's go training. Again, depending of the amount of data used, the model complexity and computational resources of the machine that you're using, this can take a while. So, relax while the computer works for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "oQI2hnRo-x4R"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Basque\n",
      "Initialization 0\n",
      "  Iteration 1\t time lapse 73.30189s\t ll change inf\n",
      "  Iteration 2\t time lapse 8.68895s\t ll change 1.15218\n",
      "  Iteration 3\t time lapse 9.61829s\t ll change 0.08570\n",
      "  Iteration 4\t time lapse 9.95696s\t ll change 0.05529\n",
      "  Iteration 5\t time lapse 8.42709s\t ll change 0.03925\n",
      "  Iteration 6\t time lapse 7.47265s\t ll change 0.02934\n",
      "  Iteration 7\t time lapse 6.68119s\t ll change 0.02297\n",
      "  Iteration 8\t time lapse 5.59268s\t ll change 0.01888\n",
      "  Iteration 9\t time lapse 5.25276s\t ll change 0.01633\n",
      "  Iteration 10\t time lapse 5.55500s\t ll change 0.01467\n",
      "  Iteration 11\t time lapse 5.07637s\t ll change 0.01346\n",
      "  Iteration 12\t time lapse 5.03804s\t ll change 0.01260\n",
      "  Iteration 13\t time lapse 5.22409s\t ll change 0.01185\n",
      "  Iteration 14\t time lapse 5.05203s\t ll change 0.01096\n",
      "  Iteration 15\t time lapse 5.40471s\t ll change 0.00992\n",
      "  Iteration 16\t time lapse 5.97293s\t ll change 0.00877\n",
      "  Iteration 17\t time lapse 5.68412s\t ll change 0.00771\n",
      "  Iteration 18\t time lapse 6.73708s\t ll change 0.00680\n",
      "  Iteration 19\t time lapse 6.22393s\t ll change 0.00606\n",
      "  Iteration 20\t time lapse 5.83183s\t ll change 0.00551\n",
      "Initialization converged: False\t time lapse 196.79259s\t ll 18.59685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ritas\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:274: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Catalan\n",
      "Initialization 0\n",
      "  Iteration 1\t time lapse 59.78723s\t ll change inf\n",
      "  Iteration 2\t time lapse 6.29204s\t ll change 0.57845\n",
      "  Iteration 3\t time lapse 6.32317s\t ll change 0.08636\n",
      "  Iteration 4\t time lapse 6.00979s\t ll change 0.05617\n",
      "  Iteration 5\t time lapse 6.20843s\t ll change 0.04075\n",
      "  Iteration 6\t time lapse 5.44429s\t ll change 0.03116\n",
      "  Iteration 7\t time lapse 6.48769s\t ll change 0.02459\n",
      "  Iteration 8\t time lapse 6.77299s\t ll change 0.01994\n",
      "  Iteration 9\t time lapse 6.43100s\t ll change 0.01681\n",
      "  Iteration 10\t time lapse 6.81444s\t ll change 0.01444\n",
      "  Iteration 11\t time lapse 4.28952s\t ll change 0.01227\n",
      "  Iteration 12\t time lapse 5.04007s\t ll change 0.01042\n",
      "  Iteration 13\t time lapse 4.80625s\t ll change 0.00893\n",
      "  Iteration 14\t time lapse 4.26414s\t ll change 0.00773\n",
      "  Iteration 15\t time lapse 4.23149s\t ll change 0.00680\n",
      "  Iteration 16\t time lapse 4.78048s\t ll change 0.00612\n",
      "  Iteration 17\t time lapse 4.98130s\t ll change 0.00562\n",
      "  Iteration 18\t time lapse 4.23277s\t ll change 0.00523\n",
      "  Iteration 19\t time lapse 6.03247s\t ll change 0.00492\n",
      "  Iteration 20\t time lapse 6.82610s\t ll change 0.00463\n",
      "Initialization converged: False\t time lapse 166.05567s\t ll 18.12143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ritas\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:274: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for English\n",
      "Initialization 0\n",
      "  Iteration 1\t time lapse 55.23797s\t ll change inf\n",
      "  Iteration 2\t time lapse 6.12222s\t ll change 0.80386\n",
      "  Iteration 3\t time lapse 6.13288s\t ll change 0.10704\n",
      "  Iteration 4\t time lapse 6.25633s\t ll change 0.06115\n",
      "  Iteration 5\t time lapse 6.11569s\t ll change 0.04050\n",
      "  Iteration 6\t time lapse 6.21143s\t ll change 0.02969\n",
      "  Iteration 7\t time lapse 5.52362s\t ll change 0.02308\n",
      "  Iteration 8\t time lapse 6.13115s\t ll change 0.01900\n",
      "  Iteration 9\t time lapse 6.05119s\t ll change 0.01665\n",
      "  Iteration 10\t time lapse 4.28128s\t ll change 0.01549\n",
      "  Iteration 11\t time lapse 3.78801s\t ll change 0.01460\n",
      "  Iteration 12\t time lapse 3.82133s\t ll change 0.01341\n",
      "  Iteration 13\t time lapse 3.45756s\t ll change 0.01177\n",
      "  Iteration 14\t time lapse 3.23035s\t ll change 0.01001\n",
      "  Iteration 15\t time lapse 3.78469s\t ll change 0.00833\n",
      "  Iteration 16\t time lapse 5.80233s\t ll change 0.00682\n",
      "  Iteration 17\t time lapse 6.53103s\t ll change 0.00560\n",
      "  Iteration 18\t time lapse 5.93871s\t ll change 0.00477\n",
      "  Iteration 19\t time lapse 5.89641s\t ll change 0.00425\n",
      "  Iteration 20\t time lapse 6.11027s\t ll change 0.00395\n",
      "Initialization converged: False\t time lapse 156.42444s\t ll 16.90553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ritas\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:274: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Galician\n",
      "Initialization 0\n",
      "  Iteration 1\t time lapse 41.95277s\t ll change inf\n",
      "  Iteration 2\t time lapse 4.87730s\t ll change 0.86490\n",
      "  Iteration 3\t time lapse 5.84901s\t ll change 0.09142\n",
      "  Iteration 4\t time lapse 5.67652s\t ll change 0.06253\n",
      "  Iteration 5\t time lapse 5.16739s\t ll change 0.04557\n",
      "  Iteration 6\t time lapse 5.26827s\t ll change 0.03404\n",
      "  Iteration 7\t time lapse 6.30699s\t ll change 0.02592\n",
      "  Iteration 8\t time lapse 6.19581s\t ll change 0.02027\n",
      "  Iteration 9\t time lapse 5.98065s\t ll change 0.01702\n",
      "  Iteration 10\t time lapse 5.25304s\t ll change 0.01524\n",
      "  Iteration 11\t time lapse 5.30433s\t ll change 0.01402\n",
      "  Iteration 12\t time lapse 5.55505s\t ll change 0.01286\n",
      "  Iteration 13\t time lapse 6.38332s\t ll change 0.01185\n",
      "  Iteration 14\t time lapse 5.91323s\t ll change 0.01121\n",
      "  Iteration 15\t time lapse 6.40639s\t ll change 0.01087\n",
      "  Iteration 16\t time lapse 5.46187s\t ll change 0.01142\n",
      "  Iteration 17\t time lapse 6.26658s\t ll change 0.01289\n",
      "  Iteration 18\t time lapse 5.90857s\t ll change 0.01827\n",
      "  Iteration 19\t time lapse 5.43181s\t ll change 0.01858\n",
      "  Iteration 20\t time lapse 5.61809s\t ll change 0.01266\n",
      "Initialization converged: False\t time lapse 150.77798s\t ll 17.72177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ritas\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:274: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Portuguese\n",
      "Initialization 0\n",
      "  Iteration 1\t time lapse 50.07891s\t ll change inf\n",
      "  Iteration 2\t time lapse 3.41902s\t ll change 1.49744\n",
      "  Iteration 3\t time lapse 3.20378s\t ll change 0.08033\n",
      "  Iteration 4\t time lapse 3.10018s\t ll change 0.05363\n",
      "  Iteration 5\t time lapse 2.76541s\t ll change 0.03924\n",
      "  Iteration 6\t time lapse 2.89894s\t ll change 0.03077\n",
      "  Iteration 7\t time lapse 3.02026s\t ll change 0.02567\n",
      "  Iteration 8\t time lapse 3.26415s\t ll change 0.02240\n",
      "  Iteration 9\t time lapse 2.90635s\t ll change 0.02008\n",
      "  Iteration 10\t time lapse 2.78076s\t ll change 0.01851\n",
      "  Iteration 11\t time lapse 2.64059s\t ll change 0.01730\n",
      "  Iteration 12\t time lapse 2.45977s\t ll change 0.01620\n",
      "  Iteration 13\t time lapse 2.82659s\t ll change 0.01527\n",
      "  Iteration 14\t time lapse 2.87747s\t ll change 0.01467\n",
      "  Iteration 15\t time lapse 2.67459s\t ll change 0.01436\n",
      "  Iteration 16\t time lapse 2.48740s\t ll change 0.01401\n",
      "  Iteration 17\t time lapse 2.53419s\t ll change 0.01326\n",
      "  Iteration 18\t time lapse 2.92032s\t ll change 0.01210\n",
      "  Iteration 19\t time lapse 2.90405s\t ll change 0.01071\n",
      "  Iteration 20\t time lapse 2.94845s\t ll change 0.00933\n",
      "Initialization converged: False\t time lapse 104.71118s\t ll 17.41411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ritas\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:274: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Spanish\n",
      "Initialization 0\n",
      "  Iteration 1\t time lapse 22.48796s\t ll change inf\n",
      "  Iteration 2\t time lapse 2.98358s\t ll change 0.18572\n",
      "  Iteration 3\t time lapse 2.87275s\t ll change 0.08383\n",
      "  Iteration 4\t time lapse 2.80411s\t ll change 0.04876\n",
      "  Iteration 5\t time lapse 2.94827s\t ll change 0.03329\n",
      "  Iteration 6\t time lapse 2.72973s\t ll change 0.02546\n",
      "  Iteration 7\t time lapse 2.63120s\t ll change 0.02092\n",
      "  Iteration 8\t time lapse 2.92140s\t ll change 0.01812\n",
      "  Iteration 9\t time lapse 3.07485s\t ll change 0.01600\n",
      "  Iteration 10\t time lapse 2.80054s\t ll change 0.01398\n",
      "  Iteration 11\t time lapse 2.72956s\t ll change 0.01176\n",
      "  Iteration 12\t time lapse 2.59974s\t ll change 0.00985\n",
      "  Iteration 13\t time lapse 2.79081s\t ll change 0.00832\n",
      "  Iteration 14\t time lapse 3.20116s\t ll change 0.00677\n",
      "  Iteration 15\t time lapse 3.14535s\t ll change 0.00540\n",
      "  Iteration 16\t time lapse 2.71632s\t ll change 0.00465\n",
      "  Iteration 17\t time lapse 2.64545s\t ll change 0.00412\n",
      "  Iteration 18\t time lapse 2.60270s\t ll change 0.00373\n",
      "  Iteration 19\t time lapse 3.02303s\t ll change 0.00341\n",
      "  Iteration 20\t time lapse 3.09654s\t ll change 0.00312\n",
      "Initialization converged: False\t time lapse 76.80505s\t ll 17.69796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ritas\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:274: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## TRAIN GMM models (ML) \n",
    "models = {}\n",
    "n_gauss = 64\n",
    "for lang in LANGUAGES:\n",
    "    models[lang] = GaussianMixture(n_components=n_gauss, covariance_type='diag', max_iter=20, n_init=1, init_params='kmeans', verbose=2, verbose_interval=1)\n",
    "    \n",
    "for lang in LANGUAGES:\n",
    "    print(f'Training model for {lang}')\n",
    "    models[lang].fit(train_data[train_labels==LANG2ID[lang]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fb-Jk3qi-x4R"
   },
   "source": [
    "Once the models have been trained, we can store them in disk for later usage. Again, be careful and avoid storing versions of useless models. By default, the model is stored in a folder inside the data partition folder and contains the feature extraction in the name and the date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "gN1n-thh-x4R"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models\\\\gmm_mfcc_delta1.model']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save models\n",
    "import joblib\n",
    "now = str(datetime.datetime.now()).replace(' ','_').split('.')[0]\n",
    "path = Path(CWD) / trainset / 'models'\n",
    "if not os.path.isdir(path):\n",
    "    os.mkdir(path)\n",
    "filename = 'models\\\\gmm_{}.model'.format(transform_id,now)\n",
    "joblib.dump(models, filename)\n",
    "#models=joblib.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iA7sapFK-x4R"
   },
   "source": [
    "You can also check the `sklearn` documentation and inspect the models trained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "id": "mtroAt_v-x4S"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 104)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#raise CheckThisCell ## <---- Remove this after completing/checking this cell\n",
    "models['Portuguese'].means_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABfTbk-m-x4S"
   },
   "source": [
    "## Identification and generation of the predictions file\n",
    "\n",
    "Now that we  already have trained models, let's predict/identify language in new audio data and test our model!!! \n",
    "\n",
    "But first, we need to obtain the development partition and do the feature extraction more or less as previously (using the Kalaka class).\n",
    "\n",
    "**IMPORTANT WARNING** Make sure to use the exact same feature extraction process as the one used for the train set. Otherwise, your model will be in disagreement with your evaluation data, and very likely, will not work at all.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "-jJw4-t3-x4S"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 917/917 [07:21<00:00,  2.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# Download and feature extract\n",
    "#raise CheckThisCell ##\n",
    "transform_id = 'mfcc_delta1'\n",
    "\n",
    "# Notice that the chunking is mostly useless both in training and prediction with GMMs: each frame is a sample for which we obtain the probs\n",
    "devkalaka = Kalaka(CWD,'dev', \n",
    "                 transform_id=transform_id, \n",
    "                 audio_transform=transform[transform_id]['audio_transform'], \n",
    "                 chunk_transform=transform[transform_id]['chunk_transform'],\n",
    "                 chunk_size=transform[transform_id]['chunk_size'], \n",
    "                 chunk_hop=transform[transform_id]['chunk_hop']\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfBgF7t0-x4S"
   },
   "source": [
    "Now, we can iterate the data and use the models for scoring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "BQFu7-BQ-x4S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading all data in 30.870569944381714\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "dev_data = {}\n",
    "\n",
    "for data, label, basename in devkalaka:\n",
    "        if basename not in dev_data:\n",
    "                dev_data[basename] = {'data':[], 'label':label}\n",
    "        dev_data[basename]['data'].append(data)\n",
    "\n",
    "## We concatenate all the frames belonging to the same filename\n",
    "for basename in dev_data:\n",
    "        dev_data[basename]['data'] = np.concatenate(dev_data[basename]['data'])\n",
    "\n",
    "print(f'Finished reading all data in {time.time() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "WrH2f8sI-x4S"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 917/917 [06:22<00:00,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished predicting all data in 382.2602508068085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "results_dev = {}\n",
    "results_dev['ref'] =  np.empty(len(dev_data),dtype=np.int32)\n",
    "results_dev['hyp'] =  np.empty(len(dev_data),dtype=np.int32)\n",
    "results_dev['llhs'] = np.empty((len(dev_data), len(LANGUAGES)), dtype=np.float64)\n",
    "results_dev['fileids'] = list()\n",
    "\n",
    "for i, fileid in tqdm(enumerate(sorted(dev_data)), total=len(dev_data)):\n",
    "    data = dev_data[fileid]['data']  # the features\n",
    "    \n",
    "    results_dev['fileids'].append(fileid)     #fileid\n",
    "\n",
    "    # obtain the log-likelihood score for each model and store\n",
    "    results_dev['llhs'][i,:] = np.array([models[lang].score(data) for lang in LANGUAGES])\n",
    "\n",
    "    # store the reference. Notice that I only have this for the dev set, not for the eval\n",
    "    results_dev['ref'][i] = (dev_data[fileid]['label']) #referemce\n",
    "\n",
    "    # Obtain the maximum likelihood languge estimation\n",
    "    ix = np.argmax(results_dev['llhs'][i,:])\n",
    "    results_dev['hyp'][i] = LANG2ID[LANGUAGES[ix]]\n",
    "    \n",
    "    \n",
    "print(f'Finished predicting all data in {time.time() - start}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgBeM5Pj-x4T"
   },
   "source": [
    "\n",
    "## Evaluation\n",
    "After running the previous cells, we obtain two arrays with the reference and hypothesis labels, respectively (we can also reload them in case we need them). We can use these to obtain different evaluation metrics and inspect the performance (and potential problems) of our system. Of course, you will only be able to do this evaluation with the development set, since you don't have access to the eval labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3f8B-u5-x4T"
   },
   "source": [
    "You can for instance obtain a classification report summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "3QeeA-vw-x4T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Basque       0.25      0.19      0.22       154\n",
      "     Catalan       0.21      0.18      0.19       149\n",
      "     English       0.22      0.39      0.29       150\n",
      "    Galician       0.24      0.29      0.27       151\n",
      "  Portuguese       0.24      0.12      0.16       160\n",
      "     Spanish       0.21      0.20      0.20       153\n",
      "\n",
      "    accuracy                           0.23       917\n",
      "   macro avg       0.23      0.23      0.22       917\n",
      "weighted avg       0.23      0.23      0.22       917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ref, hyp = results_dev['ref'], results_dev['hyp']\n",
    "print(classification_report(ref, hyp, target_names=LANGUAGES))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYq1UdjM-x4T"
   },
   "source": [
    "Overall accuracy (this will be the **main metric for system ranking**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "-XYYjcE5-x4T"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22791712104689205"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ref, hyp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkExiAxc-x4T"
   },
   "source": [
    "Or a confusion matrix: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTYNOQ64-x4T"
   },
   "source": [
    "and visualize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "pYRGzAli-x4T"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(ref, hyp)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3.0, 3.0))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center')\n",
    "\n",
    "plt.xlabel('Predictions', fontsize=12)\n",
    "plt.ylabel('Actuals', fontsize=12)\n",
    "plt.title(f'Confusion Matrix\\n(Accuracy {100*accuracy_score(ref, hyp):.2f})', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPbmC-r0-x4U"
   },
   "source": [
    "These results are poor. The baseline system is very limited in several aspects (features, time context, generative model, etc.). For instance, the likelihood scores are not normalized. It may happen, that one model  provides slightly higher scores for some reason. The following trick sometimes increases slightly the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "XwjX9VOqcZWe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.43693698, 0.84146899, 0.5229056 , 0.94892258, 0.41141519,\n",
       "       0.7234555 ])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dev['llhs'].std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "NPqTCPQF-x4U"
   },
   "outputs": [],
   "source": [
    "llhs_norm = (results_dev['llhs'] - results_dev['llhs'].mean(axis=0))/results_dev['llhs'].std(axis=0)\n",
    "hyp_norm = np.empty(hyp.shape, like=hyp)\n",
    "for i in range(len(results_dev['fileids'])):\n",
    "    ix = np.argmax(llhs_norm[i,:])\n",
    "    hyp_norm[i] = LANG2ID[LANGUAGES[ix]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "bf2hv7iM-x4U"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(ref, hyp_norm)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3.0, 3.0))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center')\n",
    "\n",
    "plt.xlabel('Predictions', fontsize=12)\n",
    "plt.ylabel('Actuals', fontsize=12)\n",
    "plt.title(f'Confusion Matrix\\n(Accuracy {100*accuracy_score(ref, hyp_norm):.2f})', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZC2K1rw4-x4U"
   },
   "source": [
    "This \"trick\" is probematic. Can you discuss why? Can you think of an altenative way of doing the same kind of normalization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAxi9Z6S-x4U"
   },
   "source": [
    "## Running the prediction on the evl partition\n",
    "\n",
    "Once you are happy with your system and the results obtained in the development set, you are ready to generate the predictions on the `'evl'` partition. To do that, you have to follow the same process as for the development partition, but of course, this time you will not be able to obtain performance results because you don't have labels for this partition. \n",
    "\n",
    "We start by instantiating the `Kalaka` class for the `'evl'` partition:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wlkh-7z_-x4U"
   },
   "outputs": [],
   "source": [
    "transform_id = 'mfcc_sdc_vad_chunk_300_300'\n",
    "\n",
    "evlkalaka = Kalaka(CWD,'evl', \n",
    "                 transform_id=transform_id, \n",
    "                 audio_transform=transform[transform_id]['audio_transform'], \n",
    "                 chunk_transform=transform[transform_id]['chunk_transform'],\n",
    "                 chunk_size=transform[transform_id]['chunk_size'], \n",
    "                 chunk_hop=transform[transform_id]['chunk_hop']\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5hbmkX1a-x4U"
   },
   "source": [
    "Then, we load the evaluation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MZ54EqBH-x4U"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "evl_data = {}\n",
    "\n",
    "for data, label, basename in evlkalaka:\n",
    "        if basename not in evl_data:\n",
    "                evl_data[basename] = {'data':[], 'label':label}\n",
    "        evl_data[basename]['data'].append(data)\n",
    "\n",
    "for basename in evl_data:\n",
    "        evl_data[basename]['data'] = np.concatenate(evl_data[basename]['data'])\n",
    "\n",
    "print(f'Finished reading all data in {time.time() - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9T2dC9v8-x4U"
   },
   "source": [
    "And apply the model(s) to the new `'evl'` data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x74P0U-9-x4V"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "results_evl = {}\n",
    "results_evl['ref'] =  None\n",
    "results_evl['hyp'] =  np.empty(len(evl_data),dtype=np.int32)\n",
    "results_evl['llhs'] = np.empty((len(evl_data), len(LANGUAGES)), dtype=np.float64)\n",
    "results_evl['fileids'] = list()\n",
    "\n",
    "\n",
    "# Obtain LLH matrix\n",
    "for i, fileid in tqdm(enumerate(sorted(evl_data)), total=len(evl_data)):\n",
    "\n",
    "    data = evl_data[fileid]['data']  # the features\n",
    "    results_evl['fileids'].append(fileid)     #fileid\n",
    "\n",
    "    # obtain the log-likelihood score for each model and store\n",
    "    results_evl['llhs'][i,:] = np.array([models[lang].score(data) for lang in LANGUAGES])\n",
    "\n",
    "    # Obtain the maximum likelihood languge estimation\n",
    "    ix = np.argmax(results_evl['llhs'][i,:])\n",
    "    results_evl['hyp'][i] = LANG2ID[LANGUAGES[ix]]    \n",
    "\n",
    "print(f'Finished predicting all data in {time.time() - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjzfQ10O-x4V"
   },
   "source": [
    "## Create the predictions file\n",
    "\n",
    "The predictions file used for submission and scoring is a CSV file containing the predictions of both the `dev` and `evl` partitions.\n",
    "The file has two fields: fileId and Lang. The fileId is the unique audio file identifier and the Lang field is the language prediction (numeric from 1 to 6). The predictions file name must be as follows:\n",
    "\n",
    "`T<X>_G<YY>_<SYSTEMID>.csv` \n",
    "\n",
    "where `<X>` can be 1 or 2 depending on being a system for track 1 or track 2 evaluation; `<YY>` is the students' group number (use 2 digits) and `<SYSTEMID>` is an identifying string for that submission/system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8qnlPi07-x4V"
   },
   "outputs": [],
   "source": [
    "group, system = '00', 'baseline_train100'\n",
    "with open(f'{CWD}/T1_G{group}_{system}.csv', 'w') as file:\n",
    "    csv_writer = csv.writer(file) # CSV writer\n",
    "    csv_writer.writerow(('fileId', 'Lang')) # Header of the CSV\n",
    "\n",
    "    # Save dev results\n",
    "    for i in range(len(results_dev['fileids'])):\n",
    "        csv_writer.writerow((results_dev['fileids'][i], results_dev['hyp'][i]))\n",
    "    # Save evl results\n",
    "    for i in range(len(results_evl['fileids'])):\n",
    "        csv_writer.writerow((results_evl['fileids'][i], results_evl['hyp'][i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cF7unOoQ-x4V"
   },
   "source": [
    "## Submit your prediction\n",
    "You can submit your prediction in the following Kaggle competition: https://www.kaggle.com/competitions/speech-processing-lab-2/\n",
    "\n",
    "## What should/can you do next?\n",
    "**Everything!!** Try to extend and improve the feature extraction. Try to play with the parameters. Try completely different feature extraction modules (look for openSMILE, torchaudio,). Try to increase the model complexity. Try different modeling approaches. Try to understand the impact of the different modifications. Once you are happy with your system, try to train on the full set and check the impact of adding data to your system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7YPWrwA-x4V"
   },
   "source": [
    "# PART 2 - Using pre-trained embeddings (Track 2)\n",
    "\n",
    "There exist plenty of resources and pre-trained models that can be extremely useful for our task. For instance, x-vectors are currently the state of the art approach to obtain speech embeddings that characterize very efficiently speaker or language, among others. Particularly, the following x-vector model is available and it has been trained using a large corpus of 107 languages for language identification: https://huggingface.co/speechbrain/lang-id-voxlingua107-ecapa\n",
    "\n",
    "You can obtain it from the `speechbrain` module, that you need to install now if you are using Google Colab:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ppPPXZd-ieT1"
   },
   "outputs": [],
   "source": [
    "# If you are using Google Colab, you'll have to install the speechbrain module\n",
    "raise CheckThisCell ## <---- Remove this after completing/checking this cell\n",
    "!pip install speechbrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cnOz0IE1-x4V"
   },
   "source": [
    "The following code cell imports such model and shows how to obtain an embedding vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "znpZKlMi-x4V"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The torchaudio backend is switched to 'soundfile'. Note that 'sox_io' is not supported on Windows.\n",
      "The torchaudio backend is switched to 'soundfile'. Note that 'sox_io' is not supported on Windows.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4c31b93a34f48ecb1190ffadeea6de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ain/hyperparams.yaml:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ritas\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ritas\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 1314] Um privilégio necessário não é mantido pelo cliente: 'C:\\\\Users\\\\ritas\\\\.cache\\\\huggingface\\\\hub\\\\models--speechbrain--lang-id-voxlingua107-ecapa\\\\snapshots\\\\d771b530cec097adc0088b4dbd173e242f895464\\\\hyperparams.yaml' -> 'tmp\\\\hyperparams.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [73]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspeechbrain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpretrained\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EncoderClassifier\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pad_sequence\n\u001b[1;32m----> 7\u001b[0m language_id \u001b[38;5;241m=\u001b[39m \u001b[43mEncoderClassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_hparams\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspeechbrain/lang-id-voxlingua107-ecapa\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msavedir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtmp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m signal \u001b[38;5;241m=\u001b[39m language_id\u001b[38;5;241m.\u001b[39mload_audio(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCWD\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/train100/audio/0006ebda.wav\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m emb \u001b[38;5;241m=\u001b[39m  language_id\u001b[38;5;241m.\u001b[39mencode_batch(signal)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\speechbrain\\pretrained\\interfaces.py:367\u001b[0m, in \u001b[0;36mPretrained.from_hparams\u001b[1;34m(cls, source, hparams_file, pymodule_file, overrides, savedir, use_auth_token, revision, download_only, **kwargs)\u001b[0m\n\u001b[0;32m    365\u001b[0m     clsname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m    366\u001b[0m     savedir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./pretrained_models/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclsname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhashlib\u001b[38;5;241m.\u001b[39mmd5(source\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUTF-8\u001b[39m\u001b[38;5;124m'\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mhexdigest()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 367\u001b[0m hparams_local_path \u001b[38;5;241m=\u001b[39m \u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhparams_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[43m    \u001b[49m\u001b[43msavedir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msavedir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    377\u001b[0m     pymodule_local_path \u001b[38;5;241m=\u001b[39m fetch(\n\u001b[0;32m    378\u001b[0m         filename\u001b[38;5;241m=\u001b[39mpymodule_file,\n\u001b[0;32m    379\u001b[0m         source\u001b[38;5;241m=\u001b[39msource,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    384\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m    385\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\speechbrain\\pretrained\\fetching.py:135\u001b[0m, in \u001b[0;36mfetch\u001b[1;34m(filename, source, savedir, overwrite, save_filename, use_auth_token, revision)\u001b[0m\n\u001b[0;32m    133\u001b[0m     sourcepath \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(fetched_file)\u001b[38;5;241m.\u001b[39mabsolute()\n\u001b[0;32m    134\u001b[0m     _missing_ok_unlink(destination)\n\u001b[1;32m--> 135\u001b[0m     \u001b[43mdestination\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msymlink_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43msourcepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m destination\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\pathlib.py:1403\u001b[0m, in \u001b[0;36mPath.symlink_to\u001b[1;34m(self, target, target_is_directory)\u001b[0m\n\u001b[0;32m   1398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msymlink_to\u001b[39m(\u001b[38;5;28mself\u001b[39m, target, target_is_directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   1399\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1400\u001b[0m \u001b[38;5;124;03m    Make this path a symlink pointing to the target path.\u001b[39;00m\n\u001b[0;32m   1401\u001b[0m \u001b[38;5;124;03m    Note the order of arguments (link, target) is the reverse of os.symlink.\u001b[39;00m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1403\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msymlink\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_is_directory\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 1314] Um privilégio necessário não é mantido pelo cliente: 'C:\\\\Users\\\\ritas\\\\.cache\\\\huggingface\\\\hub\\\\models--speechbrain--lang-id-voxlingua107-ecapa\\\\snapshots\\\\d771b530cec097adc0088b4dbd173e242f895464\\\\hyperparams.yaml' -> 'tmp\\\\hyperparams.yaml'"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "import speechbrain\n",
    "\n",
    "from speechbrain.pretrained import EncoderClassifier\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "language_id = EncoderClassifier.from_hparams(source=\"speechbrain/lang-id-voxlingua107-ecapa\", savedir=\"tmp\")\n",
    "\n",
    "signal = language_id.load_audio(f'{CWD}/train100/audio/0006ebda.wav')\n",
    "emb =  language_id.encode_batch(signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dx1zpGat-x4W"
   },
   "source": [
    "In fact, the model is trained for language identification of 107 languages and we could use it directly for identification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4w0Qs9GN-x4W"
   },
   "outputs": [],
   "source": [
    "prediction =  language_id.classify_batch(signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRzBkp9w-x4W"
   },
   "source": [
    "Invest some time to inspect the model and the outputs. Notice that the six target languages are included among the 107. The output indices are: \n",
    "\n",
    "```python\n",
    "XVEC_LANG_INDEX = (24,13,20,29,75,22) \n",
    "```\n",
    "\n",
    "corresponding respectively to the following languages:\n",
    "\n",
    "```python \n",
    "LANGUAGES = ('Basque',  'Catalan',  'English',  'Galician',  'Portuguese',  'Spanish')\n",
    "```\n",
    "\n",
    "Knowing this, it should be easy to obtain the predicted class among the six possible candidates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j3YPLIDc-x4W"
   },
   "outputs": [],
   "source": [
    "XVEC_LANG_INDEX = (24,13,20,29,75,22) \n",
    "\n",
    "# Obtain the predicted class out of the 6 target ones\n",
    "raise CheckThisCell ## <---- Remove this after completeing/checking this cell\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "le3NPyLl-x4W"
   },
   "source": [
    "## Using the x-vector up-stream model for language ID\n",
    "\n",
    "Let's try first something simple: use the the pre-trained model for idenfication. In this simple test, you don't need to train anyhing simply classify the dev and test sets. To do so, first configure the right transformation for the Kalaka class (one that simply loads the audio without any chunking):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xLFFtotG-x4W"
   },
   "outputs": [],
   "source": [
    "# Confifure the tranformation\n",
    "raise CheckThisCell ## <---- Remove this after completeing/checking this cell\n",
    "\n",
    "transform = { \n",
    "                'raw_xvec' :\n",
    "                {\n",
    "                    'audio_transform': None, ## <--- You need to modify this here\n",
    "                    'chunk_transform': None,\n",
    "                    'chunk_size': 0,\n",
    "                    'chunk_hop':0   \n",
    "                }\n",
    "            }\n",
    "\n",
    "# Download and feature extract\n",
    "transform_id = 'raw_xvec'\n",
    "\n",
    "devkalaka = Kalaka(CWD, 'dev', \n",
    "                 transform_id=transform_id, \n",
    "                 audio_transform=transform[transform_id]['audio_transform'], \n",
    "                 chunk_transform=transform[transform_id]['chunk_transform'],\n",
    "                 chunk_size=transform[transform_id]['chunk_size'], \n",
    "                 chunk_hop=transform[transform_id]['chunk_hop']\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DjVDRbmA-x4W"
   },
   "source": [
    "Now you have all the elements to predict langauge using the langID pre-trained model.\n",
    "In case you have access to a GPU, it may be good using a Pytorch Dataloader to batch the dev samples. \n",
    "Since the audios are of different size, we need to pass an auxiliary function to the dataloader that handles this (by adding 0s). This can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g7lj9pwMtTn3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda:0')\n",
    "else:\n",
    "  device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L4QmzN63-x4W"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def collate_batch(batch): \n",
    "    label_list, audio_list, basename_list, audiolen_list = [], [], [], []\n",
    "\n",
    "    for (_audio,_label, _basename) in batch:\n",
    "        label_list.append(_label)\n",
    "        audio_list.append(_audio)\n",
    "        basename_list.append(_basename)\n",
    "        audiolen_list.append(_audio.shape[0])\n",
    "\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    audio_list = pad_sequence(audio_list, batch_first=True, padding_value=0)\n",
    "    max_len = max(audiolen_list)\n",
    "    audiolen_list = torch.tensor([l/max_len for l in audiolen_list])\n",
    "\n",
    "    return audio_list.to(device),label_list.to(device), basename_list, audiolen_list.to(device)\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=devkalaka,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collate_batch,\n",
    "        shuffle=False  # <-- We want to keep the original order of the dev set\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "WqPFlvVmw3ob"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uIYItMwN-x4X"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "results_dev = {}\n",
    "results_dev['ref'] =  []\n",
    "results_dev['hyp'] =  []\n",
    "results_dev['fileids'] = [] \n",
    "\n",
    "for i, batch in tqdm(enumerate(dataloader), total=1+len(devkalaka)//batch_size):\n",
    "    data, label, basename, audiolen = batch\n",
    "    predictions = language_id.classify_batch(data, wav_lens=audiolen)\n",
    "    \n",
    "    # Complete the code to store the hypothesis (careful if you use argmax, you will ned to add 1 to the predicted class),\n",
    "    # the reference and the fileids. In the call to the prediction method, you should pass the audio length information, so that \n",
    "    # the padded 0s can be ignored\n",
    "    raise CheckThisCell ## <---- Remove this after completing/checking this cell\n",
    "   \n",
    "    \n",
    "print(f'Finished reading all data in {time.time() - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cyEVj9X8-x4X"
   },
   "source": [
    "And now let's see how well this model behaves on our dev partition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EtktDsLB-x4X"
   },
   "outputs": [],
   "source": [
    "ref, hyp = results_dev['ref'], results_dev['hyp']\n",
    "\n",
    "conf_matrix = confusion_matrix(ref, hyp)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3.0, 3.0))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center')\n",
    "\n",
    "plt.xlabel('Predictions', fontsize=12)\n",
    "plt.ylabel('Actuals', fontsize=12)\n",
    "plt.title(f'Confusion Matrix\\n(Accuracy {100*accuracy_score(ref, hyp):.2f})', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVTUIolZ-x4X"
   },
   "source": [
    "That was pretty impressive, right!?! And  easier than Part I of this lab! \n",
    "\n",
    "Well, here comes some bad news: you can not use this langid classifier in the challenge. However, you can use the pre-trained x-vector embeddings as a feature extractor to train your language classification system (may be a simple K-means on top of the x-vectors work well). You can also try to change the classification head of the x-vector model and fine-tune with the challenge data. You have plenty of options, but remember, any system that use these pre-trained embeddings (or any similar ones) are only valid for the Track 2 of the Challenge and the prediction file should be  namedlike this: `T2_G<YY>_<SYSTEMID>.csv` \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KkdvY5cu-x4X"
   },
   "source": [
    "# What should you deliver at the end of this lab assignment?\n",
    "You should deliver the following three elements:\n",
    "- You must submit at least one prediction file to the Kaggle competition in the format previously described: https://www.kaggle.com/competitions/speech-processing-lab-2/\n",
    "- You must submit (via Fênix) the modified notebook (or code) of your proposed systems(s).\n",
    "- You must submit a report (via Fênix) of maximum 2 pages describing your system, approaches (may be unsuccesful), lessons learnt, results on the dev partition, etc. You can use the following Overleaf template for the report: https://www.overleaf.com/latex/templates/interspeech-2023-paper-kit/kzcdqdmkqvbr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sp6kuq9u-x4X"
   },
   "source": [
    "# Contacts and support\n",
    "You can contact the professors during the classes or the office hours.\n",
    "\n",
    "Particularly, for this second laboratory assignment, you should contact Prof. Alberto Abad: alberto.abad@tecnico.ulisboa.pt\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fc82PIe1-x4X"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
